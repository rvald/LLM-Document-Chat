{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from llama_index import (\n",
    "    GPTVectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    LLMPredictor,\n",
    "    load_index_from_storage\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Load the .env file in the parent directory into the current enviroment\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "# Set the openai api key from the enviroment variable\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Notify the user that the document loading process has begun\n",
    "print(\"started the loading document process...\")\n",
    "\n",
    "# Read the data from the specified directory\n",
    "documents = SimpleDirectoryReader(\"../data/\").load_data()\n",
    "\n",
    "# Initialize the LLM predictor with the desired GPT-3.5-turbo model and temperature setting\n",
    "llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\"))\n",
    "\n",
    "# Create a service context using the initialized predictor\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n",
    "\n",
    "# Notify the user that the indexing process has begun\n",
    "print(\"started the indexing process...\")\n",
    "\n",
    "# Create an index using the loaded documents and the created service context\n",
    "index = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)\n",
    "\n",
    "# Store the created index to disk at the specified location\n",
    "print(\"storing the index to disk\")\n",
    "index.storage_context.persist(persist_dir=\"../documents-index/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notify the user that we are quering the index\n",
    "print(\"Querying the index...\")\n",
    "\n",
    "# Query the index for the provided question and store the response\n",
    "response = index.as_query_engine().query(\"Write a summary of the background and executive summary for the mammography quality act. Remember to add formatting elements so that the output is easy to read and well-formatted. Use line breaks to improve formatting.\")\n",
    "\n",
    "# Print the received response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notify the user that we are quering the index\n",
    "print(\"Querying the index...\")\n",
    "\n",
    "# Query the index for the provided question and store the response\n",
    "response = index.as_query_engine().query(\"Write a detailed summary of the mammography quality act including pages 1 thorugh 46. Please write succint bullet points after which include an executive summary which you can present? Remember to add formatting elements so that the output is easy to read and well-formatted. Use line breaks to improve formatting.\")\n",
    "\n",
    "# Print the received response\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
